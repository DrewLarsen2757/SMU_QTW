---
title: "Case2New"
author: "Matt Chinchilla"
date: "9/13/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(XML)
library(stringr)
```

Data Extraction (Execution):
Raw data extraction: After separating the data into individual rows, we had to extract the variables from the raw data. We use the headers at the top and the row with the equal signs to guide our data extraction. For most years, the breaks in the row of equal signs correspond to a new variable. We use the extract variables function below to create matrices from the raw data. The function takes the raw data that is separated by row, finds the locations of the breaks in the row with the equal signs, and uses that location as a guide where to split every line in the raw data into a new variable. These variables are then named using the header row above the equal sign line. We found that year 2001 did not have a header row, but did have the equal sign separator. 2002 and 2001 had the same header row structure, so we copy the header row from 2002 and use it for 2001. 2011 had a problem initially with parsing using UTF-8. Changing the htmlParse function in the extractResTable3 function to have encoding = 'latin1' solved the problem. It was also found that 2006 did not have a separation in the equal sign row between location and time, so we manually changed an equal sign to a space in the row so our function would automatically separate these variables. Our extractVariables function was successfully run on all raw data objects and outputted a list of individual matrices for each year. 

Clean up: After extracting raw results, the data needed significant amounts of cleaning. There were NA's and outliers all over the place. We had to assign header names and change data types. Header names were addressed in our extractVariables funcition, and the remaining variables are ("name", "home", "ag", "gun", "net", "time"). Name is the name of the runner, home is their home location, ag is their age, gun is their gun time (if applicable), net is their net time (if applicable) and time is their race time (if applicable). If we have a net time variable, we use that to calculate time in the final dataframe. If we have a gun time variable but no net time varabile, we use that to calculate time in the final dataframe. If we don't have a gun or net time but we have a time variable, we use that to caluculate time in the final dataframe. After addressing header names, we changed the age variable to numeric. We had to do some data parsing to change the time variable to numeric as well: the data came in as hours:minutes:seconds. We were interested in analyzing the time variable in terms of minutes, so we multipled hours by 60, divided seconds by 60 and kept the minutes, and added those 3 variables together to get total minutes. This result was then turned into a numeric varialbe. 

Missing values and outliers: There were outliers and NA values in both of our numeric columns: age and time. These needed to be dealt with. Looking at box plots, it was clear that 2003 was definitely an issue, and 2009, 2001 and 2011 could potentially be issues with young runners. To deal with 2003, we found that the age column fluxuated by a column in either direction as we went down the raw data. Increasing the search by 1 column for the age variable solved the issue with 2003 and 2011. In 2001, there was a racer with an age of 0. When we went back and looked at the raw data, it was found that this racer was listed as 0, so we just removed this racer from the data. In 2011, there was a racer that was 7 years old. This was confirmed in the raw data. While the racer was young, it was determined that it was possible for a 7 year old to run a 10 mile race, so the data point was kept. There were still a few outliers in the data frame, but those were kept in there for analysis in our EDA. Now that we dealt with NA's and outliers in the age variable, we decided to look at the time variable. Stars and hashtags in the time variable were messing up our multiplication initially. Removing those in the initial time calculation function removed a singificant amount of NA's in many years. There were still NA's in 2002 and 2006. 2006 had times that were in the location variable. It was determined that the data wasn't being parsed correctly due to a missing break in the equal sign row. The break was manually inputted, which fixed the NA's in 2006. The one remaining NA in 2002 was a footer line, which was removed. Looking at box plots of the run times by year, nothing stood out as problematic in terms of outliers, so we proceed with our analysis. 


Function to find the location of column names
```{r}
findColLocs = 
  function(spacerRow)
    {
    spaceLocs = gregexpr(" ", spacerRow)[[1]] 
    rowLength = nchar(spacerRow)
    
    if (substring(spacerRow, rowLength, rowLength) != "") 
      return( c(0, spaceLocs, rowLength + 1)) 
    else return(c(0, spaceLocs))  } 

```

Function to select the columns for the final analysis
```{r}
selectCols =  function(colNames, headerRow, searchLocs)  {  
  sapply(colNames,  function(name, headerRow, searchLocs) 
  {  startPos = regexpr(name, headerRow)[[1]]  
    if (startPos == -1)  return( c(NA, NA)) 
  index = sum(startPos >= searchLocs) 
  c(searchLocs[index] + 1, searchLocs[index + 1])  }, 
  headerRow = headerRow, 
  searchLocs = searchLocs) 
  } 


```

Function to convert time from %h:%m:%s to minutes. 
```{r}
parseTime = function(timePieces){
if (length(timePieces) == 2) timePieces[1] + timePieces[2]/60
else 
60*timePieces[1] + timePieces[2] + timePieces[3]/60
}
convertTime = 
function(useTime) {
timePieces = strsplit(useTime, ":")
timePieces = sapply(timePieces, as.numeric)
sapply(timePieces, parseTime)
}
```

Function to create the final dataframe for analysis
```{r}
createDF =
function(Res, year, sex)
{
# Determine which time to use
useTime = if( !is.na(Res[1, 'net']) )
Res[ , 'net']
else if( !is.na(Res[1, 'gun']) )
Res[ , 'gun']
else
Res[ , 'time']
# Remove # and * and blanks from time
useTime = gsub("[#\\*[:blank:]]", "", useTime)
# Drop rows with no time
Res = Res[ useTime != "", ]
runTime = convertTime(useTime[ useTime != "" ])
Results = data.frame(year = rep(year, nrow(Res)),
sex = rep(sex, nrow(Res)),
name = Res[ , 'name'],
home = Res[ , 'home'],
age = as.numeric(Res[, 'ag']),
runTime = runTime,
stringsAsFactors = FALSE)
invisible(Results)
}
```

Function to extract variables from the full initial raw data
```{r}
extractVariables =
function(file, varNames =c("name", "home", "ag", "gun",
"net", "time"))
{
# Find the index of the row with =s

eqIndex = grep("^===", file)
# Extract the two key rows and the data
spacerRow = file[eqIndex]
file = file[grep('^#', file, invert = TRUE)]

headerRow = tolower(file[ eqIndex - 1 ])
body = file[ -(1 : eqIndex) ]
# Obtain the starting and ending positions of variables
searchLocs = findColLocs(spacerRow)
locCols = selectCols(varNames, headerRow, searchLocs)
Values = mapply(substr, list(body), start = locCols[1, ], stop = locCols[2, ])
colnames(Values) = varNames
invisible(Values)
}
```


URLS for scrapping data
```{r}
ubase = "http://www.cherryblossom.org/"

#### From text
F_URLs = 
  c("results/1999/cb99f.html", 
    "results/2000/Cb003f.htm", 
    "results/2001/oof_f.html",
    "results/2002/ooff.htm", 
    "results/2003/CB03-F.HTM",
    "results/2004/women.htm", 
    "results/2005/CB05-F.htm", 
    "results/2006/women.htm", 
    "results/2007/women.htm", 
    "results/2008/women.htm", 
    "results/2009/09cucb-F.htm",
    "results/2010/2010cucb10m-f.htm", 
    "results/2011/2011cucb10m-f.htm",
    "results/2012/2012cucb10m-f.htm")

urls = paste(ubase,F_URLs, sep = "")

years = 1999:2012
```



Function to pull and parse inital data from the URLs
```{r}
extractResTable3 =  
  #Retrieve data from web site, 
  #find the preformatted text,  
  #and return as a character vector.  
  function(url, year)  {  
    doc = htmlParse(url, encoding = 'latin1')      

    
    if (year == 2000) { 

    #Get text from 4th font element 
    #File is ill-formed so <pre> search doesnâ€™t work.  
    ff = getNodeSet(doc, "//font")  
    txt = xmlValue(ff[[4]]) 
    els = strsplit(txt, "\r\n")[[1]]  
    }  
    
    else if (year == 1999) { 

      # Get preformatted text from <pre> elements
      pres = getNodeSet(doc, "//pre")
      txt = xmlValue(pres[[1]])
      els1 = strsplit(txt, "\n") 
      els = els1[[1]]
    } 
      else if (year == 2011) { 
      # Get preformatted text from <pre> elements
      pres = getNodeSet(doc, "//pre")
      txt = xmlValue(pres[[1]])
      els1 = strsplit(txt, "\r\n") 
      els = els1[[1]]
    } 
    
  else {  

  preNode = getNodeSet(doc, "//pre")  
  txt = xmlValue(preNode[[1]]) 
  els = strsplit(txt, "\r\n")[[1]]  
  }  
  return(els) 
  } 

```

Run extracResTable3 function and check character lenght count. Note: 1999 does not parse correctly the code chunk below this chunk will pull the 1999 data correctly.
```{r}
wTables3 = mapply(extractResTable3, url = urls, year = years)
names(wTables3) = 1999:2012
sapply(wTables3, length)
```

IGNORE: Drew work to figure out why 1999 was parsing weird
```{r}
extractResTable3(urls[1], years[1])
length(wTables3$`1999`)
els1 = strsplit(txt, "\n") 
els1
```
IGNORE: Drew work to figure out why 1999 was parsing weird
```{r}
doc = htmlParse(urls[1], encoding = 'UTF-8')  
pres = getNodeSet(doc, "//pre")
txt = xmlValue(pres[[1]])
els1 = strsplit(txt, "\n") 
els = els1[[1]]
length(els)
```

IGNORE: Initial NA handling
```{r}
eqIndex = grep("^===", wTables3$"2008") 

spacerRow = wTables3$'2008'[eqIndex] 
headerRow = wTables3$'2008'[eqIndex - 1]  
body = wTables3$'2008'[ -(1:eqIndex)] 
findColLocs(eqIndex)
```
2001, 2011 are problems
2001 error handling: no header
```{r}
table = extractVariables(wTables3$`2004`)
wTables3$`2001`[3] = wTables3$`2002`[3]
wTables3$`2001`[2] = wTables3$`2002`[2]
table = extractVariables(wTables3$`2001`)
head(wTables3$`2001`)
```

IGNORE: 2011 handling: invalid multibyte string. Handled in initial call; had to change encoding to latin1
```{r}
table = extractVariables(wTables3$`2011`)
```

2006 time handling. See analysis later
```{r}
wTables3$`2006`[8] = '===== ======== ====== ====================== == =============== ======= ======== ===== = '
wTables3$`2006`[1:10]
```

Applying the extract varaiables function to the raw data 
```{r}
womenResMat = lapply(wTables3, extractVariables)
sapply(womenResMat, nrow)
```
#####################################################
Data cleaning!
Initial analysis: 2003 is clearly an issue. 2001 might be an issue with young people racing. 2009 and 2011 are questionable. Lets start with 03. Looking at the actual website, the age moves around quite a bit. We expand the age search to 1 more column, which fixes the dataframe. 
```{r}
age = sapply(womenResMat,function(x) as.numeric(x[ , 'ag']))
boxplot(age, ylab = "Age", xlab = "Year")
```
Our 2003 fix seemed to help 2011 as well. 2001 and 2009 are still potential problems. It looks like many of the NA's are the result of people not entering their age, or rows that are header/footer rows.  After removing header/footer rows, it looks like there are still a few NA's per year. Examining the worst of these years, 2005, it seems like all the NA's are actually missing ages for the people that ran. We'll keep them in for now but in our age analysis we will remove them. 
```{r}
sapply(age, function(x) sum(is.na(x)))
age1999 = age[["2005"]]
header = grep("^===", wTables3[['2005']])
badAgeIndex = which(is.na(age1999)) + header
badAgeIndex
wTables3[['2005']][ badAgeIndex ]
```
2009 and 2001 have low ages. There is only one low age in each of the dataframes, so I think it's worth it just to treat these as outliers and replace their age with what is listed on the website. In this case, #2611 in 2001 was listed as 0 and #6619 in 2009 was listed as 7, and she ran a 2 hour race. Why can't a 7 year old run a 2 hour 10 mile race? We'll keep it in the data.
```{r}
age2001 = age$`2001`
which(age2001 < 10)
age2009 = age$`2009`
which(age2009 < 10)
eqIndex09 = grep("^===", wTables3[['2009']])
eqIndex01 = grep("^===", wTables3[['2001']])
womenResMat[['2001']][ which(age2001 < 10), ] 
womenResMat[['2009']][ which(age2009 < 10), ] 
wTables3[['2001']][ which(age2001 < 10) + eqIndex01 ] 
wTables3[['2009']][ which(age2009 < 10) + eqIndex09 ] 
womenResMat$`2001` = womenResMat$`2001`[-c(2611),]
```

Double checking the boxplot to make sure all the ages look good. They do. We can proceed and look at the time variable. 
```{r}
age = sapply(womenResMat,function(x) as.numeric(x[ , 'ag']))
boxplot(age, ylab = "Age", xlab = "Year")
```
###############################################################
Time Analysis
When trying to apply the createDF function to the women data, we get a bunch of NA's. What's going on?
```{r}
womendf = mapply(createDF, womenResMat, year = 1999:2012, sex = rep('F', 14), SIMPLIFY = FALSE)

```
Looks like we run into some issues converting time. Let's remove stars and hashtags from the time columns. 
```{r}
sapply(womendf, function(x) sum(is.na(x$runTime)))
```
After removing stars and hashtags, it looks like we have one left in 2002 and a few more in 2006. 
```{r}
womendf = mapply(createDF, womenResMat, year = 1999:2012, sex = rep('F', 14), SIMPLIFY = FALSE)
sapply(womendf, function(x) sum(is.na(x$runTime)))
```
It's a footer line. We can go ahead and remove it. 
```{r}
womendf$`2002`[is.na(womendf$`2002`$runTime),]
womendf$`2002` = womendf$`2002`[-c(3335),]
```


Alright, now we're left with a ton of NA's in the 2006 dataframe. 
```{r}
sapply(womendf, function(x) sum(is.na(x$runTime)))
```
It looks like the time is in the home column because there's no break in the = signs between hometown and net time. Space #64 needs to be turned into a blank. 

```{r}
time = sapply(womendf,function(x) as.numeric(x[ , 'runTime']))
boxplot(time, ylab = "time", xlab = "Year")
```
Runtimes look normal. 
```{r}
time = sapply(womendf,function(x) as.numeric(x[ , 'runTime']))
boxplot(time, ylab = "time", xlab = "Year")
```
Final NA check, some are left in the age column. 
```{r}

sapply(womendf, function(x) sum(is.na(x)))

womendf$`2006`[which(is.na(womendf$`2006`$runTime)),]
womenResMat$`2006`[which(is.na(womendf$`2006`$runTime)),]

```
Create a full single dataframe with all data with year and sex as added columns. 
```{r}
womendf
nawomendf = lapply(womendf, function(x) na.omit(x))
class(nawomendf)

fullwomendf = do.call(rbind, womendf)
fullwomendf
write.csv(fullwomendf, 'Case2_FullDataFrame.csv')
```
