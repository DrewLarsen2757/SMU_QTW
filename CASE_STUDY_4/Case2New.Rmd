---
title: "Case2New"
author: "Matt Chinchilla"
date: "9/13/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(XML)
library(stringr)
library(dplyr)
```

Data Extraction (Execution):
Raw data extraction: After separating the data into individual rows, we had to extract the variables from the raw data. We use the headers at the top and the row with the equal signs to guide our data extraction. For most years, the breaks in the row of equal signs correspond to a new variable. We use the extract variables function below to create matrices from the raw data. The function takes the raw data that is separated by row, finds the locations of the breaks in the row with the equal signs, and uses that location as a guide where to split every line in the raw data into a new variable. These variables are then named using the header row above the equal sign line. We found that year 2001 did not have a header row, but did have the equal sign separator. 2002 and 2001 had the same header row structure, so we copy the header row from 2002 and use it for 2001. 2011 had a problem initially with parsing using UTF-8. Changing the htmlParse function in the extractResTable3 function to have encoding = 'latin1' solved the problem. It was also found that 2006 did not have a separation in the equal sign row between location and time, so we manually changed an equal sign to a space in the row so our function would automatically separate these variables. Our extractVariables function was successfully run on all raw data objects and outputted a list of individual matrices for each year. 

Clean up: After extracting raw results, the data needed significant amounts of cleaning. There were NA's and outliers all over the place. We had to assign header names and change data types. Header names were addressed in our extractVariables funcition, and the remaining variables are ("name", "home", "ag", "gun", "net", "time"). Name is the name of the runner, home is their home location, ag is their age, gun is their gun time (if applicable), net is their net time (if applicable) and time is their race time (if applicable). If we have a net time variable, we use that to calculate time in the final dataframe. If we have a gun time variable but no net time varabile, we use that to calculate time in the final dataframe. If we don't have a gun or net time but we have a time variable, we use that to caluculate time in the final dataframe. After addressing header names, we changed the age variable to numeric. We had to do some data parsing to change the time variable to numeric as well: the data came in as hours:minutes:seconds. We were interested in analyzing the time variable in terms of minutes, so we multipled hours by 60, divided seconds by 60 and kept the minutes, and added those 3 variables together to get total minutes. This result was then turned into a numeric varialbe. 

Missing values and outliers: There were outliers and NA values in both of our numeric columns: age and time. These needed to be dealt with. Looking at box plots, it was clear that 2003 was definitely an issue, and 2009, 2001 and 2011 could potentially be issues with young runners. To deal with 2003, we found that the age column fluxuated by a column in either direction as we went down the raw data. Increasing the search by 1 column for the age variable solved the issue with 2003 and 2011. In 2001, there was a racer with an age of 0. When we went back and looked at the raw data, it was found that this racer was listed as 0, so we just removed this racer from the data. In 2011, there was a racer that was 7 years old. This was confirmed in the raw data. While the racer was young, it was determined that it was possible for a 7 year old to run a 10 mile race, so the data point was kept. There were still a few outliers in the data frame, but those were kept in there for analysis in our EDA. Now that we dealt with NA's and outliers in the age variable, we decided to look at the time variable. Stars and hashtags in the time variable were messing up our multiplication initially. Removing those in the initial time calculation function removed a singificant amount of NA's in many years. There were still NA's in 2002 and 2006. 2006 had times that were in the location variable. It was determined that the data wasn't being parsed correctly due to a missing break in the equal sign row. The break was manually inputted, which fixed the NA's in 2006. The one remaining NA in 2002 was a footer line, which was removed. Looking at box plots of the run times by year, nothing stood out as problematic in terms of outliers, so we proceed with our analysis. 


Function to find the location of column names
```{r}
findColLocs = 
  function(spacerRow)
    {
    spaceLocs = gregexpr(" ", spacerRow)[[1]] 
    rowLength = nchar(spacerRow)
    
    if (substring(spacerRow, rowLength, rowLength) != "") 
      return( c(0, spaceLocs, rowLength + 1)) 
    else return(c(0, spaceLocs))  } 

```

Function to select the columns for the final analysis
```{r}
selectCols =  function(colNames, headerRow, searchLocs)  {  
  sapply(colNames,  function(name, headerRow, searchLocs) 
  {  startPos = regexpr(name, headerRow)[[1]]  
    if (startPos == -1)  return( c(NA, NA)) 
  index = sum(startPos >= searchLocs) 
  c(searchLocs[index] + 1, searchLocs[index + 1])  }, 
  headerRow = headerRow, 
  searchLocs = searchLocs) 
  } 


```

Function to convert time from %h:%m:%s to minutes. 
```{r}
parseTime = function(timePieces){
if (length(timePieces) == 2) timePieces[1] + timePieces[2]/60
else 
60*timePieces[1] + timePieces[2] + timePieces[3]/60
}
convertTime = 
function(useTime) {
timePieces = strsplit(useTime, ":")
timePieces = sapply(timePieces, as.numeric)
sapply(timePieces, parseTime)
}
```

Function to create the final dataframe for analysis
```{r}
createDF =
function(Res, year, sex)
{
# Determine which time to use
useTime = if( !is.na(Res[1, 'net']) )
Res[ , 'net']
else if( !is.na(Res[1, 'gun']) )
Res[ , 'gun']
else
Res[ , 'time']
# Remove # and * and blanks from time
useTime = gsub("[#\\*[:blank:]]", "", useTime)
# Drop rows with no time
Res = Res[ useTime != "", ]
runTime = convertTime(useTime[ useTime != "" ])
Results = data.frame(year = rep(year, nrow(Res)),
sex = rep(sex, nrow(Res)),
name = Res[ , 'name'],
home = Res[ , 'home'],
age = as.numeric(Res[, 'ag']),
runTime = runTime,
stringsAsFactors = FALSE)
invisible(Results)
}
```

Function to extract variables from the full initial raw data
```{r}
extractVariables =
function(file, varNames =c("name", "home", "ag", "gun",
"net", "time"))
{
# Find the index of the row with =s

eqIndex = grep("^===", file)
# Extract the two key rows and the data
spacerRow = file[eqIndex]
file = file[grep('^#', file, invert = TRUE)]

headerRow = tolower(file[ eqIndex - 1 ])
body = file[ -(1 : eqIndex) ]
# Obtain the starting and ending positions of variables
searchLocs = findColLocs(spacerRow)
locCols = selectCols(varNames, headerRow, searchLocs)
Values = mapply(substr, list(body), start = locCols[1, ], stop = locCols[2, ])
colnames(Values) = varNames
invisible(Values)
}
```


URLS for scrapping data
```{r}
ubase = "http://www.cherryblossom.org/"

#### From text
F_URLs = 
  c("results/1999/cb99f.html", 
    "results/2000/Cb003f.htm", 
    "results/2001/oof_f.html",
    "results/2002/ooff.htm", 
    "results/2003/CB03-F.HTM",
    "results/2004/women.htm", 
    "results/2005/CB05-F.htm", 
    "results/2006/women.htm", 
    "results/2007/women.htm", 
    "results/2008/women.htm", 
    "results/2009/09cucb-F.htm",
    "results/2010/2010cucb10m-f.htm", 
    "results/2011/2011cucb10m-f.htm",
    "results/2012/2012cucb10m-f.htm")

urls = paste(ubase,F_URLs, sep = "")

years = 1999:2012
```



Function to pull and parse inital data from the URLs
```{r}
extractResTable3 =  
  #Retrieve data from web site, 
  #find the preformatted text,  
  #and return as a character vector.  
  function(url, year)  {  
    doc = htmlParse(url, encoding = 'latin1')      

    
    if (year == 2000) { 

    #Get text from 4th font element 
    #File is ill-formed so <pre> search doesnâ€™t work.  
    ff = getNodeSet(doc, "//font")  
    txt = xmlValue(ff[[4]]) 
    els = strsplit(txt, "\r\n")[[1]]  
    }  
    
    else if (year == 1999) { 

      # Get preformatted text from <pre> elements
      pres = getNodeSet(doc, "//pre")
      txt = xmlValue(pres[[1]])
      els1 = strsplit(txt, "\n") 
      els = els1[[1]]
    } 
      else if (year == 2011) { 
      # Get preformatted text from <pre> elements
      pres = getNodeSet(doc, "//pre")
      txt = xmlValue(pres[[1]])
      els1 = strsplit(txt, "\r\n") 
      els = els1[[1]]
    } 
    
  else {  

  preNode = getNodeSet(doc, "//pre")  
  txt = xmlValue(preNode[[1]]) 
  els = strsplit(txt, "\r\n")[[1]]  
  }  
  return(els) 
  } 

```

Run extracResTable3 function and check character lenght count. Note: 1999 does not parse correctly the code chunk below this chunk will pull the 1999 data correctly.
```{r}
wTables3 = mapply(extractResTable3, url = urls, year = years)
names(wTables3) = 1999:2012
sapply(wTables3, length)
```

IGNORE: Drew work to figure out why 1999 was parsing weird
```{r}
extractResTable3(urls[1], years[1])
length(wTables3$`1999`)
els1 = strsplit(txt, "\n") 
els1
```
IGNORE: Drew work to figure out why 1999 was parsing weird
```{r}
doc = htmlParse(urls[1], encoding = 'UTF-8')  
pres = getNodeSet(doc, "//pre")
txt = xmlValue(pres[[1]])
els1 = strsplit(txt, "\n") 
els = els1[[1]]
length(els)
```

IGNORE: Initial NA handling
```{r}
eqIndex = grep("^===", wTables3$"2008") 

spacerRow = wTables3$'2008'[eqIndex] 
headerRow = wTables3$'2008'[eqIndex - 1]  
body = wTables3$'2008'[ -(1:eqIndex)] 
findColLocs(eqIndex)
```
2001, 2011 are problems
2001 error handling: no header
```{r}
table = extractVariables(wTables3$`2004`)
wTables3$`2001`[3] = wTables3$`2002`[3]
wTables3$`2001`[2] = wTables3$`2002`[2]
table = extractVariables(wTables3$`2001`)
head(wTables3$`2001`)
```

IGNORE: 2011 handling: invalid multibyte string. Handled in initial call; had to change encoding to latin1
```{r}
table = extractVariables(wTables3$`2011`)
```

2006 time handling. See analysis later
```{r}
wTables3$`2006`[8] = '===== ======== ====== ====================== == =============== ======= ======== ===== = '
wTables3$`2006`[1:10]
```

Applying the extract varaiables function to the raw data 
```{r}
womenResMat = lapply(wTables3, extractVariables)
sapply(womenResMat, nrow)
```
#####################################################
Data cleaning!
Initial analysis: 2003 is clearly an issue. 2001 might be an issue with young people racing. 2009 and 2011 are questionable. Lets start with 03. Looking at the actual website, the age moves around quite a bit. We expand the age search to 1 more column, which fixes the dataframe. 
```{r}
age = sapply(womenResMat,function(x) as.numeric(x[ , 'ag']))
boxplot(age, ylab = "Age", xlab = "Year")
```
Our 2003 fix seemed to help 2011 as well. 2001 and 2009 are still potential problems. It looks like many of the NA's are the result of people not entering their age, or rows that are header/footer rows.  After removing header/footer rows, it looks like there are still a few NA's per year. Examining the worst of these years, 2005, it seems like all the NA's are actually missing ages for the people that ran. We'll keep them in for now but in our age analysis we will remove them. 
```{r}
sapply(age, function(x) sum(is.na(x)))
age1999 = age[["2005"]]
header = grep("^===", wTables3[['2005']])
badAgeIndex = which(is.na(age1999)) + header
badAgeIndex
wTables3[['2005']][ badAgeIndex ]
```
2009 and 2001 have low ages. There is only one low age in each of the dataframes, so I think it's worth it just to treat these as outliers and replace their age with what is listed on the website. In this case, #2611 in 2001 was listed as 0 and #6619 in 2009 was listed as 7, and she ran a 2 hour race. Why can't a 7 year old run a 2 hour 10 mile race? We'll keep it in the data.
```{r}
age2001 = age$`2001`
which(age2001 < 10)
age2009 = age$`2009`
which(age2009 < 10)
eqIndex09 = grep("^===", wTables3[['2009']])
eqIndex01 = grep("^===", wTables3[['2001']])
womenResMat[['2001']][ which(age2001 < 10), ] 
womenResMat[['2009']][ which(age2009 < 10), ] 
wTables3[['2001']][ which(age2001 < 10) + eqIndex01 ] 
wTables3[['2009']][ which(age2009 < 10) + eqIndex09 ] 
womenResMat$`2001` = womenResMat$`2001`[-c(2611),]
```

Double checking the boxplot to make sure all the ages look good. They do. We can proceed and look at the time variable. 
```{r}
age = sapply(womenResMat,function(x) as.numeric(x[ , 'ag']))
boxplot(age, ylab = "Age", xlab = "Year")
```
###############################################################
Time Analysis
When trying to apply the createDF function to the women data, we get a bunch of NA's. What's going on?
```{r}
womendf = mapply(createDF, womenResMat, year = 1999:2012, sex = rep('F', 14), SIMPLIFY = FALSE)

```
Looks like we run into some issues converting time. Let's remove stars and hashtags from the time columns. 
```{r}
sapply(womendf, function(x) sum(is.na(x$runTime)))
```
After removing stars and hashtags, it looks like we have one left in 2002 and a few more in 2006. 
```{r}
womendf = mapply(createDF, womenResMat, year = 1999:2012, sex = rep('F', 14), SIMPLIFY = FALSE)
sapply(womendf, function(x) sum(is.na(x$runTime)))
```
It's a footer line. We can go ahead and remove it. 
```{r}
womendf$`2002`[is.na(womendf$`2002`$runTime),]
womendf$`2002` = womendf$`2002`[-c(3335),]
```


Alright, now we're left with a ton of NA's in the 2006 dataframe. 
```{r}
sapply(womendf, function(x) sum(is.na(x$runTime)))
```
It looks like the time is in the home column because there's no break in the = signs between hometown and net time. Space #64 needs to be turned into a blank. 

```{r}
time = sapply(womendf,function(x) as.numeric(x[ , 'runTime']))
boxplot(time, ylab = "time", xlab = "Year")
```
Runtimes look normal. 
```{r}
time = sapply(womendf,function(x) as.numeric(x[ , 'runTime']))
boxplot(time, ylab = "time", xlab = "Year")
```
Final NA check, some are left in the age column. 
```{r}

sapply(womendf, function(x) sum(is.na(x)))

womendf$`2006`[which(is.na(womendf$`2006`$runTime)),]
womenResMat$`2006`[which(is.na(womendf$`2006`$runTime)),]

```
Create a full single dataframe with all data with year and sex as added columns. 
```{r}
womendf
nawomendf = lapply(womendf, function(x) na.omit(x))
class(nawomendf)

fullwomendf = do.call(rbind, womendf)
fullwomendf
```
##############################################################
Analysis: Have the ages of runners changed over the years?
Looking at the box plot below, there isn't a lot of evidence that the mean age has changed year over year. We will run a more formal analysis to see if this is true or not.
```{r}
age = sapply(womenResMat,function(x) as.numeric(x[ , 'ag']))
boxplot(age, ylab = "Age", xlab = "Year")
```
We are interested in running an ANOVA test to see if there is a statistical difference between the mean age in any year. First, we look at assumtptions. The 3 assumptions are that the observations are independently and randomly drawn from the population, the data is normally distributed in each year, and the populations have a common variance. Looking at the boxplot above, the data visually look to have a common variance, but there does seem to be a skew toward higher values in these distributions. I don't think ht's enough of a right skew to be a problem, so we continue as if the populations are normal. As far as independence goes, we know that the populations have gotten larger as time has gone on, but I don't think that the age distribution of one race would depend on the age distribution of another. Also, these data were not randomly chosen from a population, but due to the nature of the data (the population of the ages of people running the race each year), it wouldn't make sense to do a random selection technique. Therefore, I think we can run an ANOVA test in order to compare these year's distribution of age. 
```{r}
model = aov(age ~ year, data = fullwomendf)
summary(model)
```
Using our ANOVA test, it appears that there is a statisticall significant difference in the mean age per year. Which years?
We use the Bonferroni correction for multiple comparisons. Bonferroni was chosen due to it being a fairly conservative test: we want to make sure that the ages are different and the difference between ages in each year isn't due to us running many tests. It seems that the further the year is away, the more likely that the year has a significantly different age. 
```{r}
tmodel = pairwise.t.test(fullwomendf$age, fullwomendf$year, p.adjust.method = 'bonferroni', alternative = 'two.sided')
tmodel
```
We ran the first analysis to find where differences were. This analysis looks at which years have higher ages. It looks like the ages aren't getting higher over time. The only statistically significant times where age got higher as year got higher is comparing 2008 to 2011 and 2012, 2009 to 2011 and 2012, and 2010 to 2012. 
```{r}
tmodel = pairwise.t.test(fullwomendf$age, fullwomendf$year, p.adjust.method = 'bonferroni', alternative =  'greater')
tmodel
```
Typically, it looks like age gets younger or stay the same as we move into the future. The outliers here is that 2011 and 2012 seem to have gotten older compared to 2008, 2009 and 2010. 
```{r}
tmodel = pairwise.t.test(fullwomendf$age, fullwomendf$year, p.adjust.method = 'bonferroni', alternative =  'less')
tmodel
```
We have statistically significant differences, but are the differences practical? The mean age seemed to float around 35 for 1999 - 2002, then drop down to 34ish for 2004 and 2005, then drop down below 34 for 2006 - 2010, bottoming out at 33.07 in 2009. The age then begins to come back up in 2010, 2011 and 2012, where the mean age is 33.88. Is a difference of a year or two different enough to make differences to the race strucutre? I expect 2013 to have a mean age between 33.5 - 34. 
```{r}
na.omit(fullwomendf) %>% group_by(year) %>% summarize(age = mean(age))
```





##############################################################
Analysis: Have the times of runners changed over the years?
Looking at the boxplot below, it doesn't look as if run time has changed over time. We run a more formal statistical analysis to check if times have changed statistically. 
```{r}
time = sapply(womendf,function(x) as.numeric(x[ , 'runTime']))
boxplot(time, ylab = "time", xlab = "Year")
```
We are interested in running an ANOVA test to see if there is a statistical difference between the mean age in any year. First, we look at assumtptions. The 3 assumptions are that the observations are independently and randomly drawn from the population, the data is normally distributed in each year, and the populations have a common variance. Looking at the boxplot above, the data visually look to have a common variance. There may have been a slightly smaller variance in early years, but I think that has more to do with the 5-10 longest times in later years being fairly high. Looking at the size of the whiskers in the box plot, they look to be fairly constant over the years. Next we look at normality. The distributions appear to be normal, aside from some rather large outliers. The 5-10 longest times wouldn't have a huge effect on the shape of the distribution, since our sample sizes per year is in the thousands. As far as independence goes, we know that the populations have gotten larger as time has gone on, but I don't think that the time distribution of one race would depend on the time distribution of another. Also, these data were not randomly chosen from a population, but due to the nature of the data (the population of the times of people running the race each year), it wouldn't make sense to do a random selection technique. Therefore, I think we can run an ANOVA test in order to compare these year's distribution of times. 
```{r}
model = aov(runTime ~ year, data = fullwomendf)
summary(model)
```
There is a statistically significant difference in the mean run time of at least one of the years. Which years? It looks like many years have statistically different times. This is a two sided test, so we are not sure if times have gotten larger or smaller, just that they're different. Now that we know they have changed in many years, we want to know how they have changed. 
```{r}
tmodel = pairwise.t.test(fullwomendf$runTime, fullwomendf$year, p.adjust.method = 'bonferroni', alternative = 'two.sided')
tmodel
```
Looking into the future, it seems that in general, times have gotten larger. Comparing 1999 to future years, all years from 2004 - 2012 have a statistically significant increase in run time. 
```{r}
tmodel = pairwise.t.test(fullwomendf$runTime, fullwomendf$year, p.adjust.method = 'bonferroni', alternative =  'greater')
tmodel
```
Looking at years where run time has decreased as we look into the future, only 2000 is less than 1999, 2007 is less than 2005 and 2006, and 2012 is less than 2010 and 2011. The trend seems to be an increasing mean time as we move into the future, aside from 2000, 2007 and 2012 being slight outliers. 
```{r}
tmodel = pairwise.t.test(fullwomendf$runTime, fullwomendf$year, p.adjust.method = 'bonferroni', alternative =  'less')
tmodel
```
We know that there is a statistically significant increase in mean run time as years increase. Is there a practical difference? The lowest mean run time is about 94 minutes in 2000, while the longest mean run time is about 100 minutes in 2011. In a ten mile race, that is a mean increase of 42 seconds per mile. Is that a big enough difference to make changes in your race, considering that change occurred over 11 years? I expect 2013 to have a mean run time between 99 and 100 minutes for the 10 mile race. 
```{r}
na.omit(fullwomendf) %>% group_by(year) %>% summarize(runTime = mean(runTime))
```